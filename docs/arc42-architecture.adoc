= Architecture Documentation: JobRunr Controller Extension
:toc: left
:toclevels: 3
:sectnums:
:icons: font
:source-highlighter: rouge

== Introduction and Goals

=== Requirements Overview

The JobRunr Control Extension is a web-based control application that extends the standard JobRunr Pro Dashboard with advanced scheduling and monitoring capabilities.
The application provides a dedicated user interface for planning, parameterizing, and monitoring jobs while using JobRunr API as the single source of truth without maintaining its own job data.

.Key Features
* Dynamic job scheduling with type-safe parameter configuration
* Support for scheduled and externally triggerable jobs
* Batch job execution with real-time progress monitoring
* External trigger API for integration with external systems
* Deep-link integration with JobRunr Pro Dashboard for detailed job analysis

=== Quality Goals

[cols="1,3,1"]
|===
|Priority |Quality Goal |Motivation

|1
|Maintainability
|Clean Architecture ensures that changes remain local and the system can evolve independently

|2
|Reliability
|Jobs must be scheduled correctly and executed reliably; JobRunr Pro provides durability guarantees

|3
|Usability
|Simple, functional UI for internal users without unnecessary complexity

|4
|Performance
|Non-blocking architecture for intensive operations (batch progress analysis)

|5
|Testability
|Hexagonal architecture enables isolated unit and integration testing
|===

=== Stakeholders

[cols="1,2,2"]
|===
|Role |Contact |Expectations

|Operations Team
|Internal Users
|Reliable job scheduling, clear monitoring interface, minimal training required

|Developers
|Development Team
|Clean codebase, clear architecture, easy to extend with new job types

|External Systems
|Integration Partners
|REST API for triggering jobs and checking status

|System Administrators
|Infrastructure Team
|Easy deployment, containerization support, monitoring capabilities
|===

== Architecture Constraints

=== Technical Constraints

[cols="1,3"]
|===
|Constraint |Description

|Java 21+
|Required for modern language features (Records, Pattern Matching, Virtual Threads)

|Quarkus 3.30.6
|Framework choice mandated by technical specification

|JobRunr Pro 8.4.0
|Licensed job scheduling engine, provides core functionality

|Server-Side Rendering
|Qute templates with htmx for interactivity (no SPA framework)
|===

=== Organizational Constraints

[cols="1,3"]
|===
|Constraint |Description

|Clean Architecture
|Mandatory architectural pattern per technical specification

|No Field Injection
|Constructor injection required for better testability

|No Lombok
|Java Records and standard patterns preferred

|License Management
|JobRunr Pro requires license file configuration
|===

=== Conventions

[cols="1,3"]
|===
|Constraint |Description

|Package Structure
|Strict layer separation: domain / application / infrastructure / adapter

|Testing Strategy
|JUnit 5 + Mockito for unit tests, QuarkusTest for integration tests

|Logging
|slf4j Logging with structured logging principles

|Documentation
|English for all public APIs and documentation
|===

== System Scope and Context

=== Business Context

[plantuml,business-context,svg]
----
@startuml
!include <C4/C4_Context>

Person(ops_user, "Operations User", "Schedules and monitors jobs via UI")
Person(admin, "Administrator", "Manages system configuration and access")
System_Ext(external_system, "External System", "Triggers jobs via REST API")

System_Boundary(jobrunr_control, "JobRunr Control") {
    System(control_app, "Scheduler Extension", "Web UI and API for job control")
}

System_Ext(jobrunr_dashboard, "JobRunr Pro Dashboard", "Built-in JobRunr monitoring UI")
System_Ext(jorunr_runtime, "JorRunr Runtime", "JobRunr storage provider")

Rel(ops_user, control_app, "Creates and monitors jobs", "HTTPS")
Rel(admin, control_app, "Configures access", "HTTPS")
Rel(external_system, control_app, "Triggers jobs", "REST API")

Rel(control_app, jobrunr_dashboard, "Deep-links for details", "HTTP")
Rel(control_app, jorunr_runtime, "Reads/writes job data", "API calls")
Rel(jobrunr_dashboard, jorunr_runtime, "Reads/writes job data", "API calls")

@enduml
----

.External Interfaces
[cols="1,2,2"]
|===
|Interface |Partner |Description

|Web UI
|Operations Users
|HTML/htmx interface for job scheduling and monitoring

|REST API
|External Systems
|Trigger endpoints for external job execution

|Deep Links
|JobRunr Dashboard
|Navigation to detailed job views in original dashboard

|Database
|JorRunr Database
|JobRunr storage provider (shared with JobRunr Dashboard)
|===

=== Technical Context

[plantuml,technical-context,svg]
----
@startuml
!include <C4/C4_Container>

Person(user, "User", "Operations Team")

System_Boundary(control, "JobRunr Control Application") {
    Container(web_ui, "Web UI", "Qute + htmx", "Server-side rendered interface")
    Container(rest_api, "REST API", "JAX-RS", "External trigger endpoints")
    Container(app_layer, "Application Layer", "Use Cases", "Business logic orchestration")
    Container(domain_layer, "Domain Layer", "Ports & Models", "Core business rules")
    Container(infra_layer, "Infrastructure", "JobRunr Adapters", "JobRunr integration")
}

ContainerDb(db, "JorRunr Database", "Relational DB", "JobRunr storage")
System_Ext(jobrunr, "JobRunr Pro", "Job execution engine")

Rel(user, web_ui, "Uses", "HTTPS")
Rel(user, rest_api, "Triggers", "HTTPS/JSON")
Rel(web_ui, app_layer, "Calls")
Rel(rest_api, app_layer, "Calls")
Rel(app_layer, domain_layer, "Uses")
Rel(app_layer, infra_layer, "Uses ports")
Rel(infra_layer, jobrunr, "Schedules jobs", "JobRunr API")
Rel(infra_layer, db, "Queries job data", "JDBC")
Rel(jobrunr, db, "Persists jobs", "JDBC")

@enduml
----

.Technical Interfaces
[cols="1,2,2,2"]
|===
|Interface |Technology |Protocol |Description

|Web Browser
|HTML5, Bootstrap 5.3, htmx 1.9.x
|HTTP/HTTPS
|User interface rendered server-side with partial updates via htmx

|REST API
|JAX-RS (REST-Jackson)
|HTTP/JSON
|OpenAPI 3.0 documented endpoints for external triggers

|JobRunr Scheduler
|JobRunr Pro API (JobScheduler, JobRequestScheduler)
|In-Process
|Job scheduling and lifecycle management

|JobRunr Storage
|JobRunr StorageProvider
|JDBC
|Read/write access to job metadata and state

|Database
|JDBC, Agroal Connection Pool
|TCP/PostgreSQL Wire Protocol
|JorRunr Database (PostgreSQL 16) connection with pooling
|===

== Solution Strategy

=== Technology Decisions

[cols="1,2,2"]
|===
|Decision |Rationale |Consequences

|Clean Architecture / Hexagonal
|Mandated by specification; ensures maintainability and testability
|Clear layer boundaries, dependency inversion via ports/adapters

|Server-Side Rendering (Qute + htmx)
|Simple, functional UI without SPA complexity; faster time-to-market
|Lower frontend complexity, reduced JavaScript, better SEO

|JobRunr Pro
|Enterprise-grade job scheduling with durability, monitoring, and batch support
|Licensing cost, vendor lock-in, but proven reliability

|Java Records
|Immutable DTOs with minimal boilerplate (Java 21 feature)
|Cleaner code, type safety, no need for Lombok

|Constructor Injection
|Better testability and explicit dependencies
|Slightly more verbose but clearer dependency graphs

|PostgreSQL
|Reliable, ACID-compliant RDBMS with excellent JobRunr support
|Standard operational tooling, backup strategies
|===

=== Architectural Patterns

==== Hexagonal Architecture (Ports and Adapters)

The application strictly follows Clean Architecture principles with dependency inversion:

[plantuml,hexagonal-architecture,svg]
----
@startuml
package "Domain Layer (Core)" {
    [JobDefinition]
    [ScheduledJobInfo]
    [JobExecutionInfo]
    [JobSchedulerPort] <<interface>>
    [JobExecutionPort] <<interface>>
    [JobDefinitionDiscoveryService] <<interface>>
}

package "Application Layer" {
    [CreateScheduledJobUseCase]
    [GetScheduledJobsUseCase]
    [ExecuteJobImmediatelyUseCase]
    [GetBatchProgressUseCase]
}

package "Infrastructure Layer" {
    [JobRunrSchedulerAdapter]
    [JobRunrExecutionAdapter]
    [JobDefinitionDiscoveryAdapter]
    [JobInvoker]
}

package "Adapter Layer (UI/API)" {
    [ScheduledJobsController]
    [JobExecutionsController]
    [ExternalTriggerResource]
}

package "External" {
    database "JorRunr Database" as DB
    component "JobRunr API" as JobRunr
}

[CreateScheduledJobUseCase] --> [JobSchedulerPort]
[GetScheduledJobsUseCase] --> [JobSchedulerPort]
[ExecuteJobImmediatelyUseCase] --> [JobSchedulerPort]
[GetBatchProgressUseCase] --> [JobExecutionPort]

[JobRunrSchedulerAdapter] ..|> [JobSchedulerPort]
[JobRunrExecutionAdapter] ..|> [JobExecutionPort]
[JobDefinitionDiscoveryAdapter] ..|> [JobDefinitionDiscoveryService]

[JobRunrSchedulerAdapter] --> JobRunr
[JobRunrExecutionAdapter] --> DB
[JobRunrSchedulerAdapter] --> DB

[ScheduledJobsController] --> [CreateScheduledJobUseCase]
[ScheduledJobsController] --> [GetScheduledJobsUseCase]
[JobExecutionsController] --> [GetBatchProgressUseCase]
[ExternalTriggerResource] --> [ExecuteJobImmediatelyUseCase]

@enduml
----

==== Use Case Driven Design

Each user interaction is modeled as a distinct use case in the application layer:

* `CreateScheduledJobUseCase` - Schedule new job
* `UpdateScheduledJobUseCase` - Modify existing scheduled job
* `DeleteScheduledJobUseCase` - Remove scheduled job
* `ExecuteJobImmediatelyUseCase` - Trigger job execution
* `GetScheduledJobsUseCase` - Retrieve all scheduled jobs
* `GetJobExecutionHistoryUseCase` - Retrieve execution history
* `GetBatchProgressUseCase` - Asynchronously load batch progress

== Building Block View

=== Level 1: System Overview

[plantuml,building-blocks-l1,svg]
----
@startuml
package "JobRunr Control Application" {
    [Domain Layer]
    [Application Layer]
    [Infrastructure Layer]
    [Adapter Layer]
}

[Domain Layer] <-- [Application Layer]
[Application Layer] <-- [Adapter Layer]
[Infrastructure Layer] ..|> [Domain Layer] : implements ports

database "JorRunr Database" as DB
component "JobRunr Pro" as JobRunr

[Infrastructure Layer] --> JobRunr
[Infrastructure Layer] --> DB

@enduml
----

=== Level 2: Domain Layer

[plantuml,domain-layer,svg]
----
@startuml
package "ch.css.jobrunr.control.domain" {
    class JobDefinition <<record>> {
        +String type
        +Boolean isBatch
        +Set<JobParameter> parameters
    }

    class ScheduledJobInfo <<record>> {
        +UUID jobId
        +String jobName
        +String jobType
        +Instant scheduledAt
        +Map<String,Object> parameters
        +boolean isExternallyTriggerable
    }

    class JobExecutionInfo {
        +UUID jobId
        +String jobName
        +String jobType
        +JobStatus status
        +Instant startedAt
        +Instant finishedAt
        +Optional<BatchProgress> batchProgress
        +Map<String,Object> parameters
    }

    class JobParameter <<record>> {
        +String name
        +JobParameterType type
        +boolean required
    }

    enum JobParameterType {
        STRING
        INTEGER
        BOOLEAN
        DATE
        DATETIME
    }

    enum JobStatus {
        ENQUEUED
        PROCESSING
        SUCCEEDED
        FAILED
    }

    interface JobSchedulerPort {
        +UUID scheduleJob(...)
        +void updateJob(...)
        +void deleteScheduledJob(UUID)
        +void executeJobNow(UUID)
        +List<ScheduledJobInfo> getScheduledJobs()
        +ScheduledJobInfo getScheduledJobById(UUID)
    }

    interface JobExecutionPort {
        +List<JobExecutionInfo> getJobExecutions()
        +Optional<JobExecutionInfo> getJobExecutionById(UUID)
    }

    interface JobDefinitionDiscoveryService {
        +List<JobDefinition> getAllJobDefinitions()
        +Optional<JobDefinition> findJobByType(String)
    }

    JobDefinition *-- JobParameter
    JobParameter --> JobParameterType
    JobExecutionInfo --> JobStatus
}
@enduml
----

=== Level 2: Application Layer

[plantuml,application-layer,svg]
----
@startuml
package "ch.css.jobrunr.control.application" {
    package "scheduling" {
        class CreateScheduledJobUseCase {
            -JobSchedulerPort schedulerPort
            -JobParameterValidator validator
            +UUID execute(jobType, jobName, params, trigger, time)
        }

        class UpdateScheduledJobUseCase {
            -JobSchedulerPort schedulerPort
            -JobParameterValidator validator
            +void execute(jobId, jobType, jobName, params, trigger, time)
        }

        class DeleteScheduledJobUseCase {
            -JobSchedulerPort schedulerPort
            +void execute(jobId)
        }

        class ExecuteJobImmediatelyUseCase {
            -JobSchedulerPort schedulerPort
            +void execute(jobId)
        }
    }

    package "monitoring" {
        class GetScheduledJobsUseCase {
            -JobSchedulerPort schedulerPort
            +List<ScheduledJobInfo> execute()
        }

        class GetJobExecutionHistoryUseCase {
            -JobExecutionPort executionPort
            +List<JobExecutionInfo> execute()
        }

        class GetBatchProgressUseCase {
            -JobExecutionPort executionPort
            -Duration timeout
            +Optional<BatchProgress> execute(jobId)
            +Uni<Optional<BatchProgress>> executeAsync(jobId)
        }
    }

    package "validation" {
        class JobParameterValidator {
            +void validate(JobDefinition, Map<String,Object>)
        }
    }
}
@enduml
----

=== Level 2: Infrastructure Layer

[plantuml,infrastructure-layer,svg]
----
@startuml
package "ch.css.jobrunr.control.infrastructure" {
    package "scheduler" {
        class JobRunrSchedulerAdapter {
            -JobScheduler jobScheduler
            -StorageProvider storageProvider
            -JobInvoker jobInvoker
            +UUID scheduleJob(...)
            +void updateJob(...)
            +void deleteScheduledJob(UUID)
            +void executeJobNow(UUID)
            +List<ScheduledJobInfo> getScheduledJobs()
            -ScheduledJobInfo mapToScheduledJobInfo(Job)
        }

        class JobInvoker {
            -JobRequestScheduler requestScheduler
            -JobDefinitionDiscoveryAdapter discoveryAdapter
            +JobId scheduleJob(jobId, type, params, isBatch, time)
            -JobRequest createRequestInstance(Class, Map)
            -Object convertToType(Object, Class)
        }
    }

    package "execution" {
        class JobRunrExecutionAdapter {
            -StorageProvider storageProvider
            -JobDefinitionDiscoveryService discoveryService
            -String dashboardUrl
            +List<JobExecutionInfo> getJobExecutions()
            +Optional<JobExecutionInfo> getJobExecutionById(UUID)
            -BatchProgress extractBatchProgress(Job)
        }
    }

    package "discovery" {
        class JobDefinitionDiscoveryAdapter {
            -Instance<ConfigurableJob> jobHandlers
            -Set<JobDefinition> jobDefinitionsCache
            +List<JobDefinition> getAllJobDefinitions()
            +Optional<JobDefinition> findJobByType(String)
            -Set<JobDefinition> discoverJobs()
        }

        interface ConfigurableJob<T> {
            +void run(T request)
            +Class<T> getJobRequestType()
        }
    }

    class JobParameterExtractor {
        +{static} Map<String,Object> extractParameters(Job)
    }
}

JobRunrSchedulerAdapter --> JobInvoker
JobRunrExecutionAdapter --> JobParameterExtractor
JobDefinitionDiscoveryAdapter --> ConfigurableJob
@enduml
----

=== Level 3: Batch Job Scheduling Workaround

Due to limitations in JobRunr's batch job API, a specific workaround is implemented for scheduling batch jobs.
This is one of the most critical design decisions in the system.

[plantuml,batch-workaround,svg]
----
@startuml
!theme plain

participant "JobInvoker" as Invoker
participant "JobRequestScheduler\n(JobRunr API)" as Scheduler
participant "JobRequest" as Request
participant "BatchJob" as Batch

note over Invoker, Batch
    **Problem**: JobRunr's startBatch() creates immediate batch parent,
    but we need to schedule batch jobs for future execution
end note

group Scheduled Batch Job (Future Date)
    Invoker -> Invoker: Check: isBatch && !isImmediate
    Invoker -> Request: Create JobRequest instance
    Invoker -> Scheduler: schedule(scheduledAt, jobRequest)
    note right
        Uses schedule() instead of startBatch()
        Batch parent will be created when job executes
    end note
    Scheduler --> Invoker: JobId
end

group Immediate Batch Job
    Invoker -> Invoker: Check: isBatch && isImmediate
    Invoker -> Request: Create JobRequest instance
    Invoker -> Scheduler: startBatch(jobRequest)
    note right
        Uses startBatch() to create batch parent immediately
        Preparer job enqueued with parent relationship
    end note
    Scheduler -> Batch: Create BatchJob parent
    Scheduler --> Invoker: JobId (batch parent)
end

group Regular (Non-Batch) Job
    Invoker -> Request: Create JobRequest instance
    Invoker -> Scheduler: schedule(scheduledAt, jobRequest)
    Scheduler --> Invoker: JobId
end

@enduml
----

.Workaround Implementation Details
[source,java]
----
public JobId scheduleJob(UUID jobId, String jobType, Map<String, Object> parameters,
                         Boolean isBatchJob, Instant scheduledAt) {
    Class<? extends JobRequest> requestClass = discoveryAdapter.getJobRequestClass(jobType);
    JobRequest jobRequest = createRequestInstance(requestClass, parameters);

    boolean isImmediate = scheduledAt == null || scheduledAt.isBefore(Instant.now().plusSeconds(5));

    JobId resultId;
    if (jobId != null) {
        // Update: always use scheduleOrReplace
        resultId = jobRequestScheduler.scheduleOrReplace(jobId, scheduledAt, jobRequest);
    } else if (isBatchJob && isImmediate) {
        // WORKAROUND: For immediate batch jobs, use startBatch()
        resultId = jobRequestScheduler.startBatch(jobRequest);
    } else {
        // For scheduled batch jobs or regular jobs, use schedule()
        // Batch parent will be created when the job executes
        resultId = jobRequestScheduler.schedule(
            scheduledAt != null ? scheduledAt : Instant.now(),
            jobRequest
        );
    }

    return resultId;
}
----

== Runtime View

=== Scenario: Schedule a New Batch Job

[plantuml,schedule-batch-job,svg]
----
@startuml
actor "Operations User" as User
participant "ScheduledJobsController" as Controller
participant "CreateScheduledJobUseCase" as UseCase
participant "JobParameterValidator" as Validator
participant "JobSchedulerPort" as Port
participant "JobRunrSchedulerAdapter" as Adapter
participant "JobInvoker" as Invoker
participant "JobRequestScheduler\n(JobRunr)" as Scheduler
database "JorRunr Database" as DB

User -> Controller: POST /scheduled/create\n(jobType, jobName, params, scheduledAt)
Controller -> UseCase: execute(jobType, jobName, params, ...)
UseCase -> Validator: validate(jobDefinition, params)
Validator --> UseCase: validation OK
UseCase -> Port: scheduleJob(jobDefinition, jobName, ...)
Port -> Adapter: scheduleJob(...)
Adapter -> Invoker: scheduleJob(null, jobType, params, true, scheduledAt)

alt Immediate Batch Job (scheduledAt < now + 5s)
    Invoker -> Scheduler: startBatch(jobRequest)
    Scheduler -> DB: INSERT batch parent job
    Scheduler --> Invoker: JobId
else Scheduled Batch Job (future date)
    Invoker -> Scheduler: schedule(scheduledAt, jobRequest)
    note right
        Batch parent NOT created yet
        Will be created when job executes
    end note
    Scheduler -> DB: INSERT scheduled job
    Scheduler --> Invoker: JobId
end

Invoker --> Adapter: JobId
Adapter -> DB: UPDATE job (set name, labels)
Adapter --> Port: UUID
Port --> UseCase: UUID
UseCase --> Controller: UUID
Controller --> User: HTTP 200 + htmx fragment

@enduml
----

=== Scenario: Execute Batch Job with Progress Monitoring

[plantuml,batch-execution,svg]
----
@startuml
participant "JobRunr Scheduler" as Scheduler
participant "CalculationBatchJob" as BatchJob
participant "CalculationItemProcessor" as Processor
database "JorRunr Database" as DB
participant "User Browser" as Browser
participant "JobExecutionsController" as Controller

note over Scheduler, DB
    Batch job execution triggered (scheduled time reached or manual)
end note

Scheduler -> BatchJob: run(request)
note right
    BatchJob has @BatchJob annotation
    Directly prepares items
end note

BatchJob -> BatchJob: Load items to process\n(e.g., 1000 items)
BatchJob -> BatchJob: Sleep 5s (simulate preparation)
BatchJob -> Scheduler: BackgroundJobRequest.enqueue(items.stream())
note right
    Enqueues child jobs (1000 items)
    All linked to batch parent
end note

loop For each item (1-1000)
    Scheduler -> DB: INSERT child job
end

BatchJob --> Scheduler: Completed
Scheduler -> DB: UPDATE batch job (SUCCEEDED)

== Parallel Execution ==

par Worker Thread 1
    Scheduler -> Processor: run(item1Request)
    Processor -> Processor: Process item 1
    Processor --> Scheduler: Success
    Scheduler -> DB: UPDATE job (SUCCEEDED)
else Worker Thread 2
    Scheduler -> Processor: run(item2Request)
    Processor -> Processor: Process item 2
    Processor --> Scheduler: Success
    Scheduler -> DB: UPDATE job (SUCCEEDED)
else Worker Thread N
    Scheduler -> Processor: run(itemNRequest)
    Processor -> Processor: Process item N
    Processor --> Scheduler: Success
    Scheduler -> DB: UPDATE job (SUCCEEDED)
end

== UI Polling ==

loop Every 2 seconds (htmx polling)
    Browser -> Controller: GET /history/batch-progress/{batchJobId}
    Controller -> DB: Query batch job stats
    DB --> Controller: BatchJobStats\n(total, succeeded, failed)
    Controller --> Browser: HTML fragment\n(progress bar update)
end

@enduml
----

=== Scenario: External Trigger API

[plantuml,external-trigger,svg]
----
@startuml
participant "External System" as External
participant "ExternalTriggerResource" as API
participant "ExecuteJobImmediatelyUseCase" as UseCase
participant "JobSchedulerPort" as Port
participant "JobRunrSchedulerAdapter" as Adapter
database "JorRunr Database" as DB
participant "JobRunr Scheduler" as Scheduler

External -> API: POST /api/external-trigger/{jobId}/trigger
API -> UseCase: execute(jobId)
UseCase -> Port: executeJobNow(jobId)
Port -> Adapter: executeJobNow(jobId)
Adapter -> DB: SELECT job WHERE id = jobId
DB --> Adapter: Job (SCHEDULED state)
Adapter -> Adapter: job.enqueue()
Adapter -> DB: UPDATE job (ENQUEUED state)
DB --> Adapter: Success
Adapter --> Port: void
Port --> UseCase: void
UseCase --> API: void
API --> External: HTTP 200 + JSON response

note over Scheduler
    Background job server picks up
    ENQUEUED job and executes
end note

Scheduler -> DB: Poll for ENQUEUED jobs
DB --> Scheduler: Job found
Scheduler -> Scheduler: Execute job
Scheduler -> DB: UPDATE job (PROCESSING → SUCCEEDED)

== Status Check ==

External -> API: GET /api/external-trigger/{jobId}/status
API -> DB: SELECT execution info
DB --> API: JobExecutionInfo (status, progress)
API --> External: HTTP 200 + JSON\n{status: "PROCESSING", progress: {...}}

@enduml
----

== Deployment View

=== Infrastructure Overview

[plantuml,deployment-view,svg]
----
@startuml
node "Container Runtime (Podman/Docker)" {
    node "Application Container" {
        component [Quarkus Application\n(JVM Mode)] as App
        component [JobRunr Background\nJob Server] as JobServer
        component [JobRunr Dashboard\n(Port 8000)] as Dashboard
    }

    database "JorRunr Database Container" {
        component [JorRunr Database (PostgreSQL 16)] as PG
        storage "JobRunr Tables" as Tables
    }
}

node "Client Browser" {
    component [Web UI] as UI
}

node "External Systems" {
    component [Trigger Client] as Trigger
}

UI --> App : HTTPS (8080)
Trigger --> App : HTTPS/REST
App --> PG : JDBC (5432)
JobServer --> PG : JDBC
Dashboard --> PG : JDBC
App ..> Dashboard : Deep-links

@enduml
----

=== Container Configuration

.Application Container
[source,dockerfile]
----
FROM registry.access.redhat.com/ubi9/openjdk-21-runtime:latest
COPY --chown=185 target/quarkus-app/lib/ /deployments/lib/
COPY --chown=185 target/quarkus-app/*.jar /deployments/
COPY --chown=185 target/quarkus-app/app/ /deployments/app/
COPY --chown=185 target/quarkus-app/quarkus/ /deployments/quarkus/
EXPOSE 8080 8000
USER 185
ENTRYPOINT ["java", "-jar", "/deployments/quarkus-run.jar"]
----

.JorRunr Database Container
[source,bash]
----
podman run -d \
  --name jobrunr-postgres \
  -e POSTGRES_PASSWORD=your_strong_password \
  -e POSTGRES_DB=postgres \
  -p 5432:5432 \
  postgres:16-alpine
----

=== Environment Configuration

[cols="2,3,2"]
|===
|Property |Description |Default

|`quarkus.datasource.jdbc.url`
|JobRunr Database JDBC connection (managed by JobRunr)
|`jdbc:postgresql://localhost:5432/jobrunr`

|`quarkus.datasource.username`
|Database username
|`postgres`

|`quarkus.datasource.password`
|Database password
|`your_strong_password`

|`quarkus.jobrunr.background-job-server.worker-count`
|Number of worker threads
|`20`

|`quarkus.jobrunr.dashboard.enabled`
|Enable JobRunr Dashboard
|`true`

|`dev.test.roles`
|Development mode user roles
|`admin`
|===

Note: All database access is managed by JobRunr Runtime.
The extension never accesses the database directly.

== Cross-cutting Concepts

=== External Trigger Convention

JobRunr does not provide a native "external trigger" flag for jobs.
To support this requirement, the application uses a date-based convention:

.Convention Rules
* Jobs scheduled for `2999-12-31T23:59:59Z` are marked as "externally triggerable"
* These jobs appear in the UI with the label "External Trigger" instead of a date
* The REST API allows triggering these jobs via POST to `+/api/external-trigger/{jobId}/trigger+`

.Implementation
[source,java]
----
public static final Instant EXTERNAL_TRIGGER = Instant.parse("2999-12-31T23:59:59Z");

private UUID createOrUpdateJob(/* other params */, boolean isExternalTrigger, Instant scheduledAt) {
    if (isExternalTrigger) {
        scheduledAt = EXTERNAL_TRIGGER;
    }
    // ... schedule job with scheduledAt
}

private boolean isExternallyTriggerable(Instant scheduledAt) {
    return scheduledAt != null && scheduledAt.equals(EXTERNAL_TRIGGER);
}
----

.Rationale
* Simple to implement without modifying JobRunr
* Date 2999-12-31 is far enough in the future to never be reached by scheduler
* Clear semantic meaning in the codebase
* Easy to filter and identify in database queries

=== Batch Job Scheduling Workaround

==== Problem Statement

JobRunr Pro provides two APIs for batch jobs:

1. `BackgroundJobRequest.startBatch(jobRequest)` - Creates batch parent immediately
2. `JobRequestScheduler.schedule(instant, jobRequest)` - Schedules job for future execution

The problem: `startBatch()` creates the batch parent job immediately, making it impossible to schedule batch jobs for future execution using the standard API.

==== Solution Approach

The system implements a conditional scheduling strategy in `JobInvoker`:

[plantuml,batch-workaround-flow,svg]
----
@startuml
start

:Receive scheduleJob request;

if (Is batch job?) then (yes)
    if (Execution time within 5 seconds?) then (yes)
        :Use startBatch();
        :Create batch parent immediately;
        note right
            Preparer job enqueued with parent context
            Child jobs will be linked to this parent
        end note
    else (no)
        :Use schedule();
        :Schedule regular job for future;
        note right
            Job will call startBatch() when it executes
            Batch parent created at execution time
        end note
    endif
else (no)
    :Use schedule();
    :Schedule regular job;
endif

:Return JobId;

stop
@enduml
----

==== Implementation Details

[source,java]
----
public JobId scheduleJob(UUID jobId, String jobType, Map<String, Object> parameters,
                         Boolean isBatchJob, Instant scheduledAt) {
    Class<? extends JobRequest> requestClass = discoveryAdapter.getJobRequestClass(jobType);
    JobRequest jobRequest = createRequestInstance(requestClass, parameters);

    // Determine if this is an immediate execution (within 5 seconds)
    boolean isImmediate = scheduledAt == null ||
                          scheduledAt.isBefore(Instant.now().plusSeconds(5));

    JobId resultId;
    if (jobId != null) {
        // Update existing job
        resultId = jobRequestScheduler.scheduleOrReplace(jobId, scheduledAt, jobRequest);
    } else if (isBatchJob && isImmediate) {
        // WORKAROUND: Immediate batch → use startBatch()
        // This creates the batch parent job immediately
        resultId = jobRequestScheduler.startBatch(jobRequest);
    } else {
        // Scheduled batch or regular job → use schedule()
        // For batch jobs: parent will be created when job executes
        resultId = jobRequestScheduler.schedule(
            scheduledAt != null ? scheduledAt : Instant.now(),
            jobRequest
        );
    }

    return resultId;
}
----

==== Batch Job Execution Flow

For scheduled batch jobs, the execution follows this pattern:

1. **Scheduled Time Reached**: JobRunr scheduler picks up the scheduled job
2. **Batch Job Executes**: `CalculationBatchJob.run(request)` is called (must be annotated with `@BatchJob`)
3. **Items Prepared**: The batch job loads and prepares all items to process
4. **Child Jobs Created**: Batch job creates all child jobs by calling `BackgroundJobRequest.enqueue(items.stream())`

[source,java]
----
@ApplicationScoped
public class CalculationBatchJob implements ConfigurableJob<CalculationBatchJobRequest> {

    @BatchJob
    @Override
    public void run(CalculationBatchJobRequest request) throws Exception {
        jobContext().logger().info(String.format("Preparing batch job with totalItems: %d, batchSize: %d, simulateErrors: %b",
                request.totalItems(), request.batchSize(), request.simulateErrors()));

        // Load all items to be processed based on request parameters
        List<CalculationItemProcessorRequest> items = IntStream.rangeClosed(1, request.totalItems())
                .mapToObj(x -> new CalculationItemProcessorRequest(x, request.simulateErrors()))
                .toList();

        // Simulate preparation delay
        try {
            Thread.sleep(5000);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }

        // Enqueue background jobs for each item
        BackgroundJobRequest.enqueue(items.stream());
    }
}
----

==== Trade-offs and Consequences

.Advantages
* ✅ Enables scheduling of batch jobs for future execution
* ✅ Preserves batch parent-child relationship
* ✅ No modifications to JobRunr required
* ✅ Works with JobRunr's batch progress tracking
* ✅ Simplified architecture - no separate preparer job needed
* ✅ Clear identification via `@BatchJob` annotation

.Disadvantages
* ❌ Batch parent is not created until execution time
* ❌ All item preparation logic must be in the batch job itself
* ❌ Cannot inspect batch structure before execution
* ❌ 5-second threshold is somewhat arbitrary

.Future Improvements
* Request JobRunr to add native support for scheduled batch jobs
* Consider making threshold configurable
* Add documentation warnings about this limitation

=== Dynamic Parameter Handling

Jobs are discovered via CDI and Java Reflection.
Parameters are extracted from `JobRequest` record components and mapped to UI form fields.

.Discovery Process
1. Scan for beans implementing `ConfigurableJob<T extends JobRequest>`
2. Extract `JobRequest` class via `getJobRequestType()`
3. Reflect on record components to extract parameter definitions
4. Map Java types to `JobParameterType` enum

.Type Mapping
[cols="2,2,2"]
|===
|Java Type |JobParameterType |UI Component

|`String`
|`STRING`
|`<input type="text">`

|`Integer`, `int`
|`INTEGER`
|`<input type="number">`

|`Boolean`, `boolean`
|`BOOLEAN`
|`<input type="checkbox">`

|`LocalDate`
|`DATE`
|`<input type="date">`

|`LocalDateTime`, `Instant`
|`DATETIME`
|`<input type="datetime-local">`

|`Enum`
|`ENUM`
|`<select>` with enum values
|===

.@JobParameter Annotation
Parameters can be annotated with `@JobParameterDefinition` to specify metadata:

[source,java]
----
public record ExampleBatchJobRequest(
        @JobParameter(defaultValue = "100")
        Integer numberOfJunks,
        @JobParameter(defaultValue = "1000")
        Integer junkSize,
        @JobParameter(defaultValue = "true")
        Boolean simulateErrors
) implements JobRequest {
    @Override
    public Class<ExampleBatchJob> getJobRequestHandler() {
        return ExampleBatchJob.class;
    }
}
----

The `@JobParameterDefinition` annotation supports:

* `name()` - Override the parameter name (defaults to field name)
* `defaultValue()` - Default value as a string (parsed to target type)

Default values are automatically parsed to the correct type:

* Strings: `"some text"`
* Booleans: `"true"` or `"false"`
* Integers: `"123"`
* Dates: `"2024-01-01"` (ISO-8601)
* DateTimes: `"2024-01-01T12:00:00"` (ISO-8601)
* Enums: `"ENUM_VALUE"` (enum constant name)

=== Server-Side Rendering Strategy

The UI uses Quarkus Qute templates with htmx for partial page updates.

.Request Flow
[plantuml,htmx-flow,svg]
----
@startuml
participant Browser
participant Controller
participant Template

Browser -> Controller: GET /scheduled
Controller -> Template: Render full page
Template --> Controller: HTML (base.html + content)
Controller --> Browser: Full HTML page

Browser -> Browser: User clicks filter

Browser -> Controller: GET /scheduled/table?filter=external\n(htmx: hx-get, hx-target)
note right
    htmx adds header: HX-Request: true
end note

Controller -> Controller: Check HX-Request header
Controller -> Template: Render fragment only
Template --> Controller: HTML fragment (table only)
Controller --> Browser: Partial HTML

Browser -> Browser: htmx replaces #table-container

@enduml
----

.Fragment Detection
[source,java]
----
@GET
@Path("/table")
public TemplateInstance getScheduledJobsTable(@Context HttpHeaders headers) {
    boolean isHtmxRequest = headers.getHeaderString("HX-Request") != null;

    if (isHtmxRequest) {
        return scheduledJobsTable.instance(); // Fragment only
    } else {
        return scheduledJobs.instance(); // Full page
    }
}
----

=== Asynchronous Batch Progress

Batch progress calculation can be IO-intensive (querying child jobs).
The system uses reactive patterns to avoid blocking:

[source,java]
----
@ApplicationScoped
public class GetBatchProgressUseCase {

    public Uni<Optional<BatchProgress>> executeAsync(UUID jobId) {
        return Uni.createFrom()
            .item(() -> execute(jobId))
            .ifNoItem().after(timeout).failWith(
                new TimeoutException("Timeout loading batch progress for job " + jobId)
            );
    }
}
----

The UI polls progress via htmx:

[source,html]
----
<div hx-get="/history/batch-progress/{jobId}"
     hx-trigger="every 2s"
     hx-swap="innerHTML">
    Loading...
</div>
----

=== Security Model

The application uses role-based access control with three roles:

[cols="1,3,2"]
|===
|Role |Permissions |Use Case

|`viewer`
|Read-only access to scheduled jobs and execution history
|Operations monitoring

|`configurator`
|Create, update, delete scheduled jobs; trigger execution
|Job configuration and management

|`admin`
|All configurator permissions + system configuration
|System administration
|===

.Controller Authorization
[source,java]
----
@Path("/scheduled")
public class ScheduledJobsController {

    @GET
    @RolesAllowed({"viewer", "configurator", "admin"})
    public TemplateInstance getScheduledJobsView() { /* ... */ }

    @POST
    @Path("/create")
    @RolesAllowed({"configurator", "admin"})
    public Response createJob(/* ... */) { /* ... */ }

    @DELETE
    @Path("/{id}")
    @RolesAllowed({"admin"})
    public Response deleteJob(@PathParam("id") UUID id) { /* ... */ }
}
----

=== API Endpoints

==== UI Endpoints

The UI is accessible at `/q/jobrunr-control/*`:

[cols="1,2,3"]
|===
|Path |Method |Description

|`/q/jobrunr-control`
|GET
|Dashboard home (redirects to scheduled jobs)

|`/q/jobrunr-control/scheduled`
|GET
|Scheduled jobs overview page

|`/q/jobrunr-control/scheduled/table`
|GET
|Scheduled jobs table fragment (htmx)

|`/q/jobrunr-control/scheduled/form`
|GET
|Job creation/edit form modal (htmx)

|`/q/jobrunr-control/scheduled/param-inputs`
|GET
|Dynamic parameter input fields (htmx)

|`/q/jobrunr-control/scheduled/create`
|POST
|Create new scheduled job

|`+/q/jobrunr-control/scheduled/{id}/update+`
|POST
|Update existing scheduled job

|`+/q/jobrunr-control/scheduled/{id}/delete+`
|DELETE
|Delete scheduled job

|`+/q/jobrunr-control/scheduled/{id}/execute+`
|POST
|Execute job immediately

|`/q/jobrunr-control/history`
|GET
|Job execution history page

|`/q/jobrunr-control/history/table`
|GET
|Execution history table fragment (htmx)

|`+/q/jobrunr-control/history/batch-progress/{id}+`
|GET
|Batch progress modal (htmx, polling)
|===

==== REST API Endpoints

The REST API is accessible at `/q/jobrunr-control/api/external-trigger/*`:

[cols="1,2,3"]
|===
|Path |Method |Description

|`+/q/jobrunr-control/api/external-trigger/{jobId}/trigger+`
|POST
|Trigger externally triggerable job immediately

|`+/q/jobrunr-control/api/external-trigger/{jobId}/status+`
|GET
|Get job execution status and progress

|`/q/openapi`
|GET
|OpenAPI 3.0 specification (Swagger)

|`/q/swagger-ui`
|GET
|Swagger UI for API testing
|===

All REST endpoints return JSON and follow OpenAPI 3.0 specification available at `/q/openapi`.
